{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAe8Vr1cIT4u"
   },
   "source": [
    "# Shallow Neural Network Implementation\n",
    "\n",
    "## Importing Required Libraries\n",
    "\n",
    "First, import the necessary libraries. Note that in this assignment, you are only allowed to use the libraries provided in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TGq-ZgsQIWEn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf_FyNaqIaje"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "In this exercise, we will use the simple yet famous **Pima Indians Diabetes** dataset. This dataset includes information from **768 Native American women** from the Pima tribe, collected to examine the risk factors for developing type 2 diabetes. The data includes age, weight, height, family history of diabetes, blood pressure, blood glucose levels, and other factors.\n",
    "\n",
    "<center>\n",
    "<div style=\"line-height:200%; font-size:medium\">\n",
    "    \n",
    "| Column | Description |\n",
    "|:------:|:-----------:|\n",
    "|Pregnancies|Number of pregnancies|\n",
    "|Glucose|Blood glucose level (mg/dL)|\n",
    "|BloodPressure|Systolic blood pressure (mmHg)|\n",
    "|SkinThickness|Skin thickness (mm)|\n",
    "|Insulin|Blood insulin level (μU/mL)|\n",
    "|BMI|Body mass index (kg/m²)|\n",
    "|DiabetesPedigreeFunction|Function representing family history of diabetes|\n",
    "|Age|Age of the woman (years)|\n",
    "|Outcome|Non-diabetic (0) or diabetic (1)|\n",
    "\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "### Reading the Dataset\n",
    "\n",
    "First, you need to read the dataset file. You can read the training data from the file `diabetes_train.csv` located in the `data` folder and use the samples in it to train the model. The model's performance will be evaluated on `diabetes_test.csv`, which has the same structure as the training data except that the `Outcome` column is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7fYf0j_6Iljd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/diabetes_train.csv')\n",
    "test_data = pd.read_csv('./data/diabetes_test.csv')\n",
    "# test_data.head()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM5Fb_wTIwoy"
   },
   "source": [
    "## Preprocessing and Feature Engineering\n",
    "\n",
    "First, store the target variable column (`Outcome`) in a separate DataFrame and then remove this column from the `train_data` DataFrame to create the equivalent matrices $X$ and $y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "IgwFWO9DI4Kq"
   },
   "outputs": [],
   "source": [
    "train_data_outcome = train_data['Outcome'].copy()\n",
    "train_data = train_data.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1TOYDG5I5cu"
   },
   "source": [
    "One of the crucial preprocessing steps is feature scaling to a normal distribution, commonly referred to as normalization. Normalization helps reduce significant weight fluctuations and accelerates model convergence. In this assignment, you should normalize each feature so that their mean is `0` and their variance is `1`. This can be done using the following formula:\n",
    "\n",
    "For a data series `X = [x_1, x_2, ..., x_n]`, subtract the mean from each data sample (`x_i`) and divide by the standard deviation (sigma) to obtain the normalized data series.\n",
    "\n",
    "$$ Z = \\frac{x_i - \\bar{x}}{\\sigma} $$\n",
    "\n",
    "**Note:** Since we only have access to the training data when building the model, use the mean and standard deviation from the training samples to normalize the test samples as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "yJddsz0JI88N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649833</td>\n",
       "      <td>0.854539</td>\n",
       "      <td>0.166518</td>\n",
       "      <td>0.900880</td>\n",
       "      <td>-0.687695</td>\n",
       "      <td>0.222281</td>\n",
       "      <td>0.438405</td>\n",
       "      <td>1.443781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.835754</td>\n",
       "      <td>-1.096441</td>\n",
       "      <td>-0.140758</td>\n",
       "      <td>0.526362</td>\n",
       "      <td>-0.687695</td>\n",
       "      <td>-0.672046</td>\n",
       "      <td>-0.370035</td>\n",
       "      <td>-0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.244068</td>\n",
       "      <td>1.938416</td>\n",
       "      <td>-0.243184</td>\n",
       "      <td>-1.283807</td>\n",
       "      <td>-0.687695</td>\n",
       "      <td>-1.093658</td>\n",
       "      <td>0.570216</td>\n",
       "      <td>-0.093184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.835754</td>\n",
       "      <td>-0.972569</td>\n",
       "      <td>-0.140758</td>\n",
       "      <td>0.151844</td>\n",
       "      <td>0.123855</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>-0.908995</td>\n",
       "      <td>-1.032441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.132872</td>\n",
       "      <td>0.513891</td>\n",
       "      <td>-1.472290</td>\n",
       "      <td>0.900880</td>\n",
       "      <td>0.762734</td>\n",
       "      <td>1.436011</td>\n",
       "      <td>5.303692</td>\n",
       "      <td>-0.007797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.649833  0.854539       0.166518       0.900880 -0.687695  0.222281   \n",
       "1    -0.835754 -1.096441      -0.140758       0.526362 -0.687695 -0.672046   \n",
       "2     1.244068  1.938416      -0.243184      -1.283807 -0.687695 -1.093658   \n",
       "3    -0.835754 -0.972569      -0.140758       0.151844  0.123855 -0.480405   \n",
       "4    -1.132872  0.513891      -1.472290       0.900880  0.762734  1.436011   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  \n",
       "0                  0.438405  1.443781  \n",
       "1                 -0.370035 -0.178571  \n",
       "2                  0.570216 -0.093184  \n",
       "3                 -0.908995 -1.032441  \n",
       "4                  5.303692 -0.007797  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in train_data.columns:\n",
    "  mean = train_data[column].mean()\n",
    "  std = train_data[column].std()\n",
    "  train_data[column] = (train_data[column] - mean) / std\n",
    "  test_data[column] = (test_data[column] - mean) / std\n",
    "  \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81ZduqxI_W1"
   },
   "source": [
    "Next, add a bias term to the DataFrame. To do this, add a column with a value of `1` at the beginning of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CXFJbXe0JDzL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649833</td>\n",
       "      <td>-0.693858</td>\n",
       "      <td>-0.550460</td>\n",
       "      <td>0.776041</td>\n",
       "      <td>0.952672</td>\n",
       "      <td>0.273386</td>\n",
       "      <td>-0.138634</td>\n",
       "      <td>0.846073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.541186</td>\n",
       "      <td>1.040346</td>\n",
       "      <td>0.473794</td>\n",
       "      <td>0.588782</td>\n",
       "      <td>0.175656</td>\n",
       "      <td>-0.122674</td>\n",
       "      <td>-0.917783</td>\n",
       "      <td>1.016847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.649833</td>\n",
       "      <td>1.380993</td>\n",
       "      <td>-0.038333</td>\n",
       "      <td>0.339103</td>\n",
       "      <td>0.762734</td>\n",
       "      <td>0.222281</td>\n",
       "      <td>0.450122</td>\n",
       "      <td>1.358395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.835754</td>\n",
       "      <td>-0.662890</td>\n",
       "      <td>-0.550460</td>\n",
       "      <td>-0.659611</td>\n",
       "      <td>-0.687695</td>\n",
       "      <td>-0.825359</td>\n",
       "      <td>0.215791</td>\n",
       "      <td>-1.032441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.838303</td>\n",
       "      <td>-1.622896</td>\n",
       "      <td>1.907751</td>\n",
       "      <td>0.151844</td>\n",
       "      <td>-0.264653</td>\n",
       "      <td>0.465027</td>\n",
       "      <td>-0.563358</td>\n",
       "      <td>1.187621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.649833 -0.693858      -0.550460       0.776041  0.952672  0.273386   \n",
       "1     1.541186  1.040346       0.473794       0.588782  0.175656 -0.122674   \n",
       "2     0.649833  1.380993      -0.038333       0.339103  0.762734  0.222281   \n",
       "3    -0.835754 -0.662890      -0.550460      -0.659611 -0.687695 -0.825359   \n",
       "4     1.838303 -1.622896       1.907751       0.151844 -0.264653  0.465027   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  bias  \n",
       "0                 -0.138634  0.846073     1  \n",
       "1                 -0.917783  1.016847     1  \n",
       "2                  0.450122  1.358395     1  \n",
       "3                  0.215791 -1.032441     1  \n",
       "4                 -0.563358  1.187621     1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bias = pd.Series(1 , index=train_data.index)\n",
    "train_data['bias'] = train_bias\n",
    "\n",
    "test_bias = pd.Series(1 , index=test_data.index)\n",
    "test_data['bias'] = test_bias\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atOwCWIKJEhG"
   },
   "source": [
    "Before designing and training the model, convert the datasets from DataFrames to NumPy arrays. Therefore, in this step, convert the DataFrames `train_data` and `train_data_outcome` to NumPy arrays. Additionally, use the `train_test_split` function to split this dataset into training and validation sets with a ratio of `0.2`.\n",
    "\n",
    "**Note:** According to previous lectures, each **row** of the input matrix represents a **feature**, and each **column** represents a **sample**. Therefore, you need to transpose the feature matrix. This step should also be applied to the target variable (`train_data_outcome`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Moa4vZOHJHx1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_data.to_numpy()\n",
    "y = train_data_outcome.to_numpy().T\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\n",
    "X_train = np.array(X_train).T\n",
    "X_validation = np.array(X_validation).T\n",
    "y_train = np.array(y_train)\n",
    "y_validation = np.array(y_validation)\n",
    "test_data_numpy = test_data.to_numpy().T\n",
    "\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# print(X_validation)\n",
    "# print(y_validation)\n",
    "#test_data_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdHMNuKjJLtk"
   },
   "source": [
    "To ensure the correctness of input and output settings, running the next cell should produce the following output:\n",
    "\n",
    "```\n",
    "X_train.shape:(9, 534), y_train.shape:(534,)\n",
    "X_validation.shape:(9, 134), y_validation.shape:(134,)\n",
    "test_data_numpy.shape:(9, 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "N3W2d5xQJMT1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:(9, 534), y_train.shape:(534,)\n",
      "X_validation.shape:(9, 134), y_validation.shape:(134,)\n",
      "test_data_numpy.shape:(9, 100)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape:{X_train.shape}, y_train.shape:{y_train.shape}')\n",
    "print(f'X_validation.shape:{X_validation.shape}, y_validation.shape:{y_validation.shape}')\n",
    "print(f'test_data_numpy.shape:{test_data_numpy.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5I0--wwJ83T"
   },
   "source": [
    "## Modeling\n",
    "\n",
    "Now that the data is processed and ready, it's time for the main part—building the model. You are required to implement a simple shallow neural network using gradient descent from scratch. We will explain each component of this model step by step to guide you through its implementation.\n",
    "\n",
    "This model is a shallow neural network with one hidden layer containing `1000` neurons. The activation function for this layer is the Rectified Linear Unit (ReLU), which you are familiar with from the activation function lectures. The activation function for the output layer is the sigmoid function. Note that the required formulas for each part are provided below. We have also implemented the two activation functions for you.\n",
    "\n",
    "```python\n",
    "sigmoid_Z = 1 / (1 + np.exp(-Z))\n",
    "```\n",
    "\n",
    "```python\n",
    "ReLU_Z = np.maximum(0, Z)\n",
    "```\n",
    "\n",
    "**Note:** Only use the NumPy library for mathematical operations and computations, and define your lists as NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvPJycbcKTGh"
   },
   "source": [
    "### Reminder: Sigmoid Function\n",
    "\n",
    "| Sigmoid Function | Derivative of Sigmoid Function |\n",
    "| :---: | :--: |\n",
    "| $f(z) = \\frac{1}{1 + e^{-z}}$ | $f'(z) = f(z)(1-f(z))$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPw_rHtcKUmZ"
   },
   "source": [
    "### Reminder: ReLU Activation Function\n",
    "\n",
    "| ReLU Function  | Derivative of ReLU Function  |\n",
    "| :---: | :--: |\n",
    "|$$f(z) = \\begin{cases} 0 & \\text{if } z < 0 \\\\ z & \\text{if } z \\geq 0\\end{cases}$$|$$f'(z) = \\begin{cases} 0 & \\text{if } z < 0 \\\\ 1 & \\text{if } z \\geq 0\\end{cases}$$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2yIwnRmKZMx"
   },
   "source": [
    "### `Model` Class Construction\n",
    "\n",
    "Create a class named `Model` that contains the following three methods. We will explain each method in detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CI6f_Ax3KgMm"
   },
   "outputs": [],
   "source": [
    "def __init__(self,input_size , hidden_size , output_size):\n",
    "    pass\n",
    "def predict(self, inputs):\n",
    "    pass\n",
    "def update_weights_for_one_epoch(self, inputs, outputs, learning_rate):\n",
    "    pass\n",
    "def fit(self, inputs, outputs, learning_rate, epochs=64):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLqB5ZibKivK"
   },
   "source": [
    "#### `__init__` Method\n",
    "\n",
    "In the `__init__(self)` method, initialize the weights of the hidden and output layers (`w1` and `w2`) randomly with a mean of `0` and a standard deviation of `0.01`. You can use the `np.random.randn` function for this purpose. Note that `np.random.randn` generates random numbers with a mean of `0` and a standard deviation of `1`, so you need to adjust these values accordingly to meet the problem requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNjFJpqfKl-o"
   },
   "source": [
    "#### `predict` Method\n",
    "\n",
    "The `predict(self, inputs)` method takes the inputs and sequentially returns the outputs of both layers (`A_1` and `A_2`). Implement this process according to the following formulas:\n",
    "\n",
    "$$Z^{[1]}=W^{[1]}.X$$\n",
    "$$A^{[1]}=ReLU(Z^{[1]})$$\n",
    "$$Z^{[2]}=W^{[2]}A^{[1]}$$\n",
    "$$A^{[2]}=\\sigma(Z^{[2]})=\\frac{1}{1+e^{-Z^{[2]}}}=Y_{pred}$$\n",
    "\n",
    "**Hint:** To perform matrix multiplication between two matrices, use the `arr1.dot(arr2)` function. For example, the formula $Z^{[1]}=W^{[1]}X$ corresponds to `W_1.dot(X)` in Python. Alternatively, you can use the `@` operator as `W_1 @ X`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_-V2fChKqsT"
   },
   "source": [
    "#### `update_weights_for_one_epoch` Method\n",
    "\n",
    "In the `update_weights_for_one_epoch(self, inputs, outputs, learning_rate)` method, update the network's weights for one epoch. Note that `learning_rate` is the learning rate or alpha. The required formulas for this section are provided below. In the next chapter, we will explain in detail how to compute them.\n",
    "\n",
    "**Weight Update for `w2`:**\n",
    "\n",
    "$$W^{[2]} = W^{[2]} + \\Delta W^{[2]}$$\n",
    "$$\\Delta W^{[2]} = - \\alpha \\frac{\\partial cost}{\\partial W^{[2]}}$$\n",
    "$$\\frac{\\partial cost}{\\partial W^{[2]}} = \\left(\\frac{-2}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right) \\bullet A^{[1]T}$$\n",
    "$$W^{[2]} = W^{[2]} + \\left(\\frac{2 \\alpha}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right) \\bullet A^{[1]T}$$\n",
    "\n",
    "**Weight Update for `w1`:**\n",
    "\n",
    "$$W^{[1]} = W^{[1]} + \\Delta W^{[1]}$$\n",
    "$$\\Delta W^{[1]} = - \\alpha \\frac{\\partial cost}{\\partial W^{[1]}}$$\n",
    "\n",
    "$$\\frac{\\partial cost}{\\partial W^{[1]}} = \\left(\\left(\\frac{-2}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right)^T \\bullet W^{[2]}\\right)^T \\odot \\frac{\\partial A^{[1]}}{\\partial Z^{[1]}} \\bullet X^T$$\n",
    "\n",
    "$$W^{[1]} = W^{[1]} + \\left(\\left(\\frac{2 \\alpha}{n}(Y_{true}-A^{[2]}) \\odot A^{[2]} \\odot (1-A^{[2]})\\right)^T \\bullet W^{[2]}\\right)^T \\odot \\frac{\\partial A^{[1]}}{\\partial Z^{[1]}} \\bullet X^T$$\n",
    "\n",
    "**Note:** The symbol $\\odot$ represents element-wise multiplication, and the symbol $\\bullet$ represents matrix multiplication.\n",
    "\n",
    "To obtain the value of $\\frac{\\partial A^{[1]}}{\\partial Z^{[1]}}$, which is the derivative of the ReLU function, use the following code snippet. This will produce a matrix of the same size as $Z^{[1]}$, composed of `0` and `1`, where cells corresponding to $Z^{[1]} > 0$ will have a value of `1`, and `0` otherwise. Note that although you pass `A_1` as input to this function, it does not affect the output.\n",
    "\n",
    "```python\n",
    "relu_gradient = np.where(A_1 > 0, 1, 0)\n",
    "```\n",
    "\n",
    "**Important:** Part of $\\Delta W^{[1]}$ is already computed in $\\Delta W^{[2]}$. By storing it, you can avoid redundant calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMV3g1W6K0Qy"
   },
   "source": [
    "#### `fit` Method\n",
    "\n",
    "The `fit(self, inputs, outputs, learning_rate, epochs=64)` method updates the network's weights for the specified number of epochs (`epochs`). You do not need to make any changes to this method; simply use it in the subsequent steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ7Z6vUxK3rW"
   },
   "source": [
    "### Model Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukBhc2a7K836"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, input_size , hidden_size , output_size):\n",
    "        self.w1 = np.random.rand(hidden_size , input_size) * 0.01\n",
    "        self.w2 = np.random.rand(output_size , hidden_size) * 0.01\n",
    " \n",
    "    def predict(self, inputs):\n",
    "        x = inputs\n",
    "        \n",
    "        Z_1 = self.w1.dot(x) # hidden layer input\n",
    "        A_1 = self.ReLU(Z_1) # hidden layer output\n",
    "\n",
    "        Z_2 = self.w2.dot(A_1) # output layer input\n",
    "        A_2 = self.Sigmoid(Z_2) # output layer output - predicted y\n",
    "\n",
    "        return A_1, A_2\n",
    "\n",
    "    def update_weights_for_one_epoch(self, inputs, outputs, learning_rate):\n",
    "        x, y_true = inputs, outputs\n",
    "        A_1, A_2 = self.predict(inputs)\n",
    "\n",
    "        n = x.shape[1]\n",
    "\n",
    "        \n",
    "        shared_coefficient = (2 * learning_rate / 2) * (y_true - A_2) * self.Sigmoid_Derivative(A_2)\n",
    "        relu_gradient = self.ReLU(A_1)\n",
    "   \n",
    "        dW2 = shared_coefficient.dot(A_1.T)\n",
    "        self.w2 += dW2\n",
    "        \n",
    "        \n",
    "        dA_1 =self.w2.T.dot(shared_coefficient)\n",
    "        dZ_1 = dA_1 * relu_gradient\n",
    "        dW1= dZ_1.dot(x.T)\n",
    "        self.w1 += dW1\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate, epochs=64):\n",
    "        for i in range(epochs):\n",
    "            self.update_weights_for_one_epoch(inputs, outputs, learning_rate)\n",
    "            \n",
    "    def Sigmoid(self , x):\n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "    \n",
    "    def Sigmoid_Derivative(self , x):\n",
    "        return x * (1 - x)    \n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0 , x)\n",
    "    \n",
    "    def ReLU_Derivative(x):\n",
    "        return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhnMZoohK_hP"
   },
   "source": [
    "### Training and Evaluation\n",
    "\n",
    "After designing the network structure, you can create an instance of the `Model()` class and then call the `fit` method with appropriate arguments to start training the model. It is recommended to experiment with different learning rates (such as `0.1`, `0.01`, `0.001`, etc.) and different numbers of training epochs, and compare the results on the validation samples.\n",
    "\n",
    "To assess the model's accuracy, you can use the `evaluation(model, inputs, outputs)` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rNZCZNy4LCeJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abolfazl\\AppData\\Local\\Temp\\ipykernel_16120\\1598900358.py:43: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model accuracy on the given set: 78.36%\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model, inputs, outputs):\n",
    "  _, A_2 = model.predict(inputs)\n",
    "  prediction = (A_2 > 0.5)\n",
    "  return np.mean(prediction == outputs) * 100\n",
    "\n",
    "input_size = X_train.shape[0]\n",
    "hidden_size = pow(10,3)\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "model = Model(input_size , hidden_size, output_size)\n",
    "model.fit(X_train, y_train, learning_rate = 0.1, epochs = 200)\n",
    "\n",
    "accuracy  = evaluation(model, X_validation, y_validation)\n",
    "print(f\"Your model accuracy on the given set: {round(accuracy , 2)}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1FMFxLLLFko"
   },
   "source": [
    "## Prediction on Test Data and Output\n",
    "\n",
    "Finally, you need to compute the model's output for the test samples. First, obtain the model's output on the test data, and then if the model predicts a higher probability that an individual has diabetes (output greater than `0.5`), classify the individual as diabetic; otherwise, classify them as non-diabetic.\n",
    "\n",
    "Therefore, in the `prediction` variable, which is a NumPy array, you will have `True` and `False` values. Note that this variable will also be evaluated by the grading system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "676HkPtxLHs_"
   },
   "outputs": [],
   "source": [
    "#accuracy  = evaluation(model,test_data_numpy , )\n",
    "#print(f\"Your model accuracy on the given set: {round(accuracy , 2)}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zfxesfSLKmy"
   },
   "source": [
    "## Assignment Grading Procedure\n",
    "\n",
    "The accuracy of your model on the test data, specifically the `prediction` variable, will also be evaluated, with a minimum acceptable accuracy of **65%**.\n",
    "\n",
    "Additionally, the `test_data` DataFrame will be checked to ensure the correctness of your data normalization process.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
